{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc4bd4f0",
   "metadata": {},
   "source": [
    "1) Demonstrate how to import Pandas and check the version of the installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a3bc97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd8ed1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chamu\\python-practice\\my_environment\\Lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INSTALLED VERSIONS\n",
      "------------------\n",
      "commit           : 8dab54d6573f7186ff0c3b6364d5e4dd635ff3e7\n",
      "python           : 3.11.0.final.0\n",
      "python-bits      : 64\n",
      "OS               : Windows\n",
      "OS-release       : 10\n",
      "Version          : 10.0.22621\n",
      "machine          : AMD64\n",
      "processor        : Intel64 Family 6 Model 126 Stepping 5, GenuineIntel\n",
      "byteorder        : little\n",
      "LC_ALL           : None\n",
      "LANG             : None\n",
      "LOCALE           : English_United States.1252\n",
      "\n",
      "pandas           : 1.5.2\n",
      "numpy            : 1.24.1\n",
      "pytz             : 2022.7.1\n",
      "dateutil         : 2.8.2\n",
      "setuptools       : 65.5.0\n",
      "pip              : 22.3\n",
      "Cython           : None\n",
      "pytest           : None\n",
      "hypothesis       : None\n",
      "sphinx           : None\n",
      "blosc            : None\n",
      "feather          : None\n",
      "xlsxwriter       : None\n",
      "lxml.etree       : None\n",
      "html5lib         : None\n",
      "pymysql          : None\n",
      "psycopg2         : None\n",
      "jinja2           : None\n",
      "IPython          : 8.8.0\n",
      "pandas_datareader: None\n",
      "bs4              : None\n",
      "bottleneck       : None\n",
      "brotli           : None\n",
      "fastparquet      : None\n",
      "fsspec           : None\n",
      "gcsfs            : None\n",
      "matplotlib       : 3.6.3\n",
      "numba            : None\n",
      "numexpr          : None\n",
      "odfpy            : None\n",
      "openpyxl         : None\n",
      "pandas_gbq       : None\n",
      "pyarrow          : None\n",
      "pyreadstat       : None\n",
      "pyxlsb           : None\n",
      "s3fs             : None\n",
      "scipy            : None\n",
      "snappy           : None\n",
      "sqlalchemy       : None\n",
      "tables           : None\n",
      "tabulate         : None\n",
      "xarray           : None\n",
      "xlrd             : None\n",
      "xlwt             : None\n",
      "zstandard        : None\n",
      "tzdata           : None\n"
     ]
    }
   ],
   "source": [
    "pd.show_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6909c73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"system\": {\n",
      "    \"commit\": \"8dab54d6573f7186ff0c3b6364d5e4dd635ff3e7\",\n",
      "    \"python\": \"3.11.0.final.0\",\n",
      "    \"python-bits\": 64,\n",
      "    \"OS\": \"Windows\",\n",
      "    \"OS-release\": \"10\",\n",
      "    \"Version\": \"10.0.22621\",\n",
      "    \"machine\": \"AMD64\",\n",
      "    \"processor\": \"Intel64 Family 6 Model 126 Stepping 5, GenuineIntel\",\n",
      "    \"byteorder\": \"little\",\n",
      "    \"LC_ALL\": null,\n",
      "    \"LANG\": null,\n",
      "    \"LOCALE\": {\n",
      "      \"language-code\": \"English_United States\",\n",
      "      \"encoding\": \"1252\"\n",
      "    }\n",
      "  },\n",
      "  \"dependencies\": {\n",
      "    \"pandas\": \"1.5.2\",\n",
      "    \"numpy\": \"1.24.1\",\n",
      "    \"pytz\": \"2022.7.1\",\n",
      "    \"dateutil\": \"2.8.2\",\n",
      "    \"setuptools\": \"65.5.0\",\n",
      "    \"pip\": \"22.3\",\n",
      "    \"Cython\": null,\n",
      "    \"pytest\": null,\n",
      "    \"hypothesis\": null,\n",
      "    \"sphinx\": null,\n",
      "    \"blosc\": null,\n",
      "    \"feather\": null,\n",
      "    \"xlsxwriter\": null,\n",
      "    \"lxml.etree\": null,\n",
      "    \"html5lib\": null,\n",
      "    \"pymysql\": null,\n",
      "    \"psycopg2\": null,\n",
      "    \"jinja2\": null,\n",
      "    \"IPython\": \"8.8.0\",\n",
      "    \"pandas_datareader\": null,\n",
      "    \"bs4\": null,\n",
      "    \"bottleneck\": null,\n",
      "    \"brotli\": null,\n",
      "    \"fastparquet\": null,\n",
      "    \"fsspec\": null,\n",
      "    \"gcsfs\": null,\n",
      "    \"matplotlib\": \"3.6.3\",\n",
      "    \"numba\": null,\n",
      "    \"numexpr\": null,\n",
      "    \"odfpy\": null,\n",
      "    \"openpyxl\": null,\n",
      "    \"pandas_gbq\": null,\n",
      "    \"pyarrow\": null,\n",
      "    \"pyreadstat\": null,\n",
      "    \"pyxlsb\": null,\n",
      "    \"s3fs\": null,\n",
      "    \"scipy\": null,\n",
      "    \"snappy\": null,\n",
      "    \"sqlalchemy\": null,\n",
      "    \"tables\": null,\n",
      "    \"tabulate\": null,\n",
      "    \"xarray\": null,\n",
      "    \"xlrd\": null,\n",
      "    \"xlwt\": null,\n",
      "    \"zstandard\": null,\n",
      "    \"tzdata\": null\n",
      "  }\n",
      "}"
     ]
    }
   ],
   "source": [
    "pd.show_versions(as_json=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fc4f4a",
   "metadata": {},
   "source": [
    "2) Transform this list, numpy array, and dictionary into a series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21b30b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "0    a\n",
      "1    b\n",
      "2    c\n",
      "3    e\n",
      "4    d\n",
      "Name: my_list, dtype: object\n",
      "<class 'pandas.core.series.Series'>\n",
      "0    0\n",
      "1    1\n",
      "2    2\n",
      "3    3\n",
      "4    4\n",
      "Name: myarr, dtype: int32\n",
      "<class 'pandas.core.series.Series'>\n",
      "a    0\n",
      "b    1\n",
      "c    2\n",
      "e    3\n",
      "d    4\n",
      "Name: mydict, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "mylist = list('abcedfghijklmnopqrstuvwxyz')\n",
    "series_list=pd.Series(mylist,name='my_list')\n",
    "print(type(series_list))\n",
    "print(series_list.head())\n",
    "myarr = np.arange(26)\n",
    "series_array=pd.Series(myarr,name='myarr')\n",
    "print(type(series_array))\n",
    "print(series_array.head())\n",
    "mydict = dict(zip(mylist, myarr))\n",
    "series_dict=pd.Series(mydict,name=\"mydict\")\n",
    "print(type(series_dict))\n",
    "print(series_dict.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17155a8",
   "metadata": {},
   "source": [
    "3) Convert the index of your previous series into a column of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db0f1395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  mydict\n",
      "0     a       0\n",
      "1     b       1\n",
      "2     c       2\n",
      "3     e       3\n",
      "4     d       4\n"
     ]
    }
   ],
   "source": [
    "df=series_dict.to_frame().reset_index()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f625f24",
   "metadata": {},
   "source": [
    "4) Combine the series below into one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d268747c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1\n",
      "0  a  0\n",
      "1  b  1\n",
      "2  c  2\n",
      "3  e  3\n",
      "4  d  4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Letters</th>\n",
       "      <th>Numbers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Letters  Numbers\n",
       "0       a        0\n",
       "1       b        1\n",
       "2       c        2\n",
       "3       e        3\n",
       "4       d        4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "ser1 = pd.Series(list('abcedfghijklmnopqrstuvwxyz'))\n",
    "ser2 = pd.Series(np.arange(26))\n",
    "df=pd.concat([ser1,ser2],axis=1)\n",
    "print(df.head())\n",
    "\n",
    "df=pd.DataFrame({'Letters' : ser1, 'Numbers':ser2})\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdd8618",
   "metadata": {},
   "source": [
    "5) Give the series below a name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b18f9c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    a\n",
       "1    b\n",
       "2    c\n",
       "3    e\n",
       "4    d\n",
       "Name: My_List, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(list('abcedfghijklmnopqrstuvwxyz'))\n",
    "ser.name='My_List'\n",
    "ser.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc8d244",
   "metadata": {},
   "source": [
    "6) Find the elements in the first series (ser1) not in the second series (ser2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1276978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser1 = pd.Series([1, 2, 3, 4, 5])\n",
    "ser2 = pd.Series([4, 5, 6, 7, 8])\n",
    "\n",
    "ser1[~ser1.isin(ser2)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d336f7dd",
   "metadata": {},
   "source": [
    "7) Find the elements in both series that are not in common (remove them if they exist in both)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28768232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "5    6\n",
       "6    7\n",
       "7    8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser1 = pd.Series([1, 2, 3, 4, 5])\n",
    "ser2 = pd.Series([4, 5, 6, 7, 8])\n",
    "\n",
    "set_u=pd.Series(np.union1d(ser1,ser2)) #union\n",
    "set_i=pd.Series(np.intersect1d(ser1,ser2)) #intersection\n",
    "\n",
    "set_u[~set_u.isin(set_i)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7188b5",
   "metadata": {},
   "source": [
    "8) Find the minimum, max, 25th percentile, and 75th percentile in the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5a1a3ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum: 0.44928746454486834\n",
      "Maximum: 21.088214585529457\n",
      "25th Percentile: 5.589429439808722\n",
      "75th Percentile: 13.108334465903383\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series(np.random.normal(10, 5, 25))\n",
    "print(\"Minimum:\", ser.min())\n",
    "print(\"Maximum:\", ser.max())\n",
    "print(\"25th Percentile:\", ser.quantile(0.25))\n",
    "print(\"75th Percentile:\", ser.quantile(0.75))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3c1803",
   "metadata": {},
   "source": [
    "9) Obtain the count of each unique item in the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "16a2880a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d    8\n",
       "e    5\n",
       "c    5\n",
       "b    3\n",
       "g    3\n",
       "h    2\n",
       "a    2\n",
       "f    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(np.take(list('abcdefgh'), np.random.randint(8, size=30)))\n",
    "ser.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449036ea",
   "metadata": {},
   "source": [
    "10) Keep the two most frequent items in the series and change all items that are not those two into \"Other\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e86f2a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent items:\n",
      "1    6\n",
      "3    2\n",
      "4    2\n",
      "2    2\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         1\n",
       "1         1\n",
       "2         1\n",
       "3         3\n",
       "4     Other\n",
       "5     Other\n",
       "6         1\n",
       "7         1\n",
       "8         1\n",
       "9         3\n",
       "10    Other\n",
       "11    Other\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.RandomState(100)\n",
    "ser = pd.Series(np.random.randint(1, 5, [12]))\n",
    "print(\"Most frequent items:\")\n",
    "print(ser.value_counts())\n",
    "ser[~ser.isin(ser.value_counts().index[:2])]='Other'\n",
    "ser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5928875",
   "metadata": {},
   "source": [
    "11) Bin the series below into 10 equal deciles and replace the values with the bin name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "979b3d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     5th\n",
       "1     3rd\n",
       "2     6th\n",
       "3     9th\n",
       "4    10th\n",
       "dtype: category\n",
       "Categories (10, object): ['1st' < '2nd' < '3rd' < '4th' ... '7th' < '8th' < '9th' < '10th']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(np.random.random(20))\n",
    "pd.qcut(ser,q=[0,.10,.20,.3,.4,.5,.6,.7,.8,.9,1],\n",
    "            labels=['1st','2nd','3rd','4th','5th','6th','7th','8th','9th','10th']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee79a87",
   "metadata": {},
   "source": [
    "12) Reshape the series ser into a dataframe with 7 rows and 5 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17a3513a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1  2  3  4\n",
      "0  7  8  2  1  9\n",
      "1  4  5  7  1  3\n",
      "2  3  1  7  6  7\n",
      "3  4  4  3  5  1\n",
      "4  9  1  8  8  2\n",
      "5  9  4  3  5  7\n",
      "6  8  5  1  9  2\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series(np.random.randint(1, 10, 35))\n",
    "df=pd.DataFrame(ser.values.reshape(7,5))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c62e92",
   "metadata": {},
   "source": [
    "13) Find the positions of numbers that are multiples of 3 from ser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ae884a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    8\n",
      "1    9\n",
      "2    1\n",
      "3    7\n",
      "4    3\n",
      "5    2\n",
      "6    8\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series(np.random.randint(1, 10, 7))\n",
    "\n",
    "print(ser)\n",
    "# np.argwhere(ser % 3==0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a60f247",
   "metadata": {},
   "source": [
    "14) From ser, extract the items at positions in list pos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42338aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     a\n",
       "4     e\n",
       "8     i\n",
       "14    o\n",
       "20    u\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(list('abcdefghijklmnopqrstuvwxyz'))\n",
    "pos = [0, 4, 8, 14, 20]\n",
    "ser.take(pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da1836c",
   "metadata": {},
   "source": [
    "15) Stack ser1 and ser2 vertically and horizontally (to form a dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5dfea534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1\n",
      "0  0  a\n",
      "1  1  b\n",
      "2  2  c\n",
      "3  3  d\n",
      "4  4  e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chamu\\AppData\\Local\\Temp\\ipykernel_12676\\2949033645.py:5: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ser1.append(ser2)\n"
     ]
    }
   ],
   "source": [
    "ser1 = pd.Series(range(5))\n",
    "ser2 = pd.Series(list('abcde'))\n",
    "\n",
    "# Vertical\n",
    "ser1.append(ser2)\n",
    "\n",
    "# Horizontal\n",
    "df = pd.concat([ser1, ser2], axis=1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c252d7bb",
   "metadata": {},
   "source": [
    "16) Get the positions of items of ser2 in ser1 as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da51891e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 4, 0, 8]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser1 = pd.Series([10, 9, 6, 5, 3, 1, 12, 8, 13])\n",
    "ser2 = pd.Series([1, 3, 10, 13])\n",
    "\n",
    "# [np.where(i == ser1)[0].tolist()[0] for i in ser2]\n",
    "\n",
    "#Other Way using pandas\n",
    "\n",
    "[pd.Index(ser1).get_loc(i) for i in ser2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098e34c8",
   "metadata": {},
   "source": [
    "17) Compute the mean squared error of truth and pred series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df7ff599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3717714177017205"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth = pd.Series(range(10))\n",
    "pred = pd.Series(range(10)) + np.random.random(10)\n",
    "\n",
    "np.mean((truth-pred)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acf6f79",
   "metadata": {},
   "source": [
    "18) Change the first character of each word to upper case in each word of ser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c210bbe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     How\n",
       "1      To\n",
       "2    Kick\n",
       "3    Ass?\n",
       "dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(['how', 'to', 'kick', 'ass?'])\n",
    "\n",
    "# Ans1:\n",
    "ser.map(lambda x: x.title())\n",
    "\n",
    "#Ans2:\n",
    "ser.map(lambda x: x[0].upper()+x[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053f198a",
   "metadata": {},
   "source": [
    "19) Caluculate the number of characters for each element in the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "216f9a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    2\n",
       "2    4\n",
       "3    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(['how', 'to', 'kick', 'ass?'])\n",
    "\n",
    "ser.map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26bcf59",
   "metadata": {},
   "source": [
    "20) Caluculate the difference of differences between the consequtive numbers of ser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c6dba0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, 2.0, 3.0, 4.0, 5.0, 6.0, 6.0, 8.0]\n",
      "[nan, nan, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0]\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series([1, 3, 6, 10, 15, 21, 27, 35])\n",
    "\n",
    "print(ser.diff().tolist())\n",
    "print(ser.diff().diff().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64a2901",
   "metadata": {},
   "source": [
    "21) Convert the date-strings to a timeseries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "db82de89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2010-01-01 00:00:00\n",
       "1   2011-02-02 00:00:00\n",
       "2   2012-03-03 00:00:00\n",
       "3   2013-04-04 00:00:00\n",
       "4   2014-05-05 00:00:00\n",
       "5   2015-06-06 12:20:00\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n",
    "\n",
    "pd.to_datetime(ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5f83c0",
   "metadata": {},
   "source": [
    "22) Get the day of month, week number, day of year and day of week from ser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4bcc124e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date:  [1, 2, 3, 4, 5, 6]\n",
      "Week number:  [53, 5, 9, 14, 19, 23]\n",
      "Day number of year:  [1, 33, 63, 94, 125, 157]\n",
      "Day of week:  [4, 2, 5, 3, 0, 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chamu\\AppData\\Local\\Temp\\ipykernel_12676\\3181641852.py:10: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  print(\"Week number: \", ser_ts.dt.weekofyear.tolist())\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n",
    "\n",
    "from dateutil.parser import parse\n",
    "ser_ts = ser.map(lambda x: parse(x))\n",
    "\n",
    "# day of month\n",
    "print(\"Date: \", ser_ts.dt.day.tolist())\n",
    "\n",
    "# week number\n",
    "print(\"Week number: \", ser_ts.dt.weekofyear.tolist())\n",
    "\n",
    "# day of year\n",
    "print(\"Day number of year: \", ser_ts.dt.dayofyear.tolist())\n",
    "\n",
    "# day of week\n",
    "print(\"Day of week: \", ser_ts.dt.day_of_week.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79f97b7",
   "metadata": {},
   "source": [
    "23) Change ser to dates that start with 4th of the respective months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a6384074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2010-01-04\n",
      "1   2011-02-04\n",
      "2   2012-03-04\n",
      "dtype: datetime64[ns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2010-01-04', '2011-02-04', '2012-03-04']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(['Jan 2010', 'Feb 2011', 'Mar 2012'])\n",
    "\n",
    "# Solution 1\n",
    "print(ser.map(lambda x: parse('04 ' + x)))\n",
    "\n",
    "# Solution 2\n",
    "from dateutil.parser import parse\n",
    "# Parse the date\n",
    "ser_ts = ser.map(lambda x: parse(x))\n",
    "\n",
    "# Construct date string with date as 4\n",
    "ser_datestr = ser_ts.dt.year.astype('str') + '-' + ser_ts.dt.month.astype('str') + '-' + '04'\n",
    "\n",
    "# Format it.\n",
    "[parse(i).strftime('%Y-%m-%d') for i in ser_datestr]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbb2f54",
   "metadata": {},
   "source": [
    "24) From ser, extract words that contain at least 2 vowels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "32dec09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Apple\n",
       "1    Orange\n",
       "4     Money\n",
       "dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(['Apple', 'Orange', 'Plan', 'Python', 'Money'])\n",
    "\n",
    "from collections import Counter\n",
    "mask = ser.map(lambda x: sum([Counter(x.lower()).get(i, 0) for i in list('aeiou')]) >= 2)\n",
    "ser[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44177063",
   "metadata": {},
   "source": [
    "25) Extract the valid emails from the series emails. The regex pattern for valid emails is provided as reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3e85fe14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                     []\n",
      "1    [rameses@egypt.com]\n",
      "2            [matt@t.co]\n",
      "3    [narendra@modi.com]\n",
      "dtype: object\n",
      "*************************************************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    rameses@egypt.com\n",
       "2            matt@t.co\n",
       "3    narendra@modi.com\n",
       "dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails = pd.Series(['buying books at amazom.com', 'rameses@egypt.com', 'matt@t.co', 'narendra@modi.com'])\n",
    "pattern ='[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Za-z]{2,4}'\n",
    "\n",
    "# Ans 1:\n",
    "import re\n",
    "print(emails.str.findall(pattern, flags=re.IGNORECASE))\n",
    "\n",
    "print(\"*************************************************\")\n",
    "\n",
    "# Ans 2:\n",
    "\n",
    "mask=emails.map(lambda x: bool(re.match(pattern,x)))\n",
    "emails[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fadf17",
   "metadata": {},
   "source": [
    "26) Compute the mean of weights of each fruit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "75855cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n",
      "['carrot', 'banana', 'carrot', 'banana', 'carrot', 'banana', 'apple', 'apple', 'banana', 'carrot']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "apple     7.50\n",
       "banana    5.25\n",
       "carrot    4.75\n",
       "dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruit = pd.Series(np.random.choice(['apple', 'banana', 'carrot'], 10))\n",
    "weights = pd.Series(np.linspace(1, 10, 10))\n",
    "print(weights.tolist())\n",
    "print(fruit.tolist())\n",
    "\n",
    "weights.groupby(fruit).mean()\n",
    "#examples\n",
    "#> [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n",
    "#> ['banana', 'carrot', 'apple', 'carrot', 'carrot', 'apple', 'banana', 'carrot', 'apple', 'carrot']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c8ebe7",
   "metadata": {},
   "source": [
    "27) Compute the euclidean distance between series (points) p and q, without using a packaged formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0c9cbfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.16590212458495\n",
      "18.16590212458495\n"
     ]
    }
   ],
   "source": [
    "p = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "q = pd.Series([10, 9, 8, 7, 6, 5, 4, 3, 2, 1])\n",
    "\n",
    "# Solution \n",
    "print(sum((p - q)**2)**.5)\n",
    "\n",
    "# Solution (using func)\n",
    "print(np.linalg.norm(p-q))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8326a3",
   "metadata": {},
   "source": [
    "28) Get the positions of peaks (values surrounded by smaller values on both sides) in ser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3ea30aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 5, 7], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series([2, 10, 3, 4, 9, 10, 2, 7, 3])\n",
    "\n",
    "dd = np.diff(np.sign(np.diff(ser)))\n",
    "peak_locs = np.where(dd == -2)[0] + 1\n",
    "peak_locs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f5675f",
   "metadata": {},
   "source": [
    "29) Replace the spaces in my_str with the least frequent character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1d4aff8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d    4\n",
      "b    3\n",
      "     3\n",
      "e    3\n",
      "a    2\n",
      "c    1\n",
      "g    1\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'dbcgdebgabedggade'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_str = 'dbc deb abed gade'\n",
    "ser = pd.Series(list('dbc deb abed gade'))\n",
    "freq = ser.value_counts()\n",
    "print(freq)\n",
    "least_freq = freq.dropna().index[-1]\n",
    "\"\".join(ser.replace(' ', least_freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146b95f0",
   "metadata": {},
   "source": [
    "30) Create a timeseries starting at ‘2000-01-01’ and 10 weekends (saturdays) after that having random numbers as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e4cd8dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-01    5\n",
       "2000-01-08    3\n",
       "2000-01-15    5\n",
       "2000-01-22    9\n",
       "2000-01-29    8\n",
       "2000-02-05    4\n",
       "2000-02-12    1\n",
       "2000-02-19    7\n",
       "2000-02-26    9\n",
       "2000-03-04    7\n",
       "Freq: W-SAT, dtype: int32"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(np.random.randint(1,10,10), pd.date_range('2000-01-01', periods=10, freq='W-SAT'))\n",
    "ser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a17176",
   "metadata": {},
   "source": [
    "31) Series ser has missing dates and values. Make all missing dates appear and fill up with value from previous date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c8a10d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-01-01     1.0\n",
      "2000-01-03    10.0\n",
      "2000-01-06     3.0\n",
      "2000-01-08     NaN\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2000-01-01     1.0\n",
       "2000-01-02     1.0\n",
       "2000-01-03    10.0\n",
       "2000-01-04    10.0\n",
       "2000-01-05    10.0\n",
       "2000-01-06     3.0\n",
       "2000-01-07     3.0\n",
       "2000-01-08     NaN\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series([1,10,3,np.nan], index=pd.to_datetime(['2000-01-01', '2000-01-03', '2000-01-06', '2000-01-08']))\n",
    "print(ser)\n",
    "\n",
    "ser.resample('D').ffill()  # fill with previous value\n",
    "\n",
    "#> 2000-01-01     1.0\n",
    "#> 2000-01-03    10.0\n",
    "#> 2000-01-06     3.0\n",
    "#> 2000-01-08     NaN\n",
    "#> dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b261ac",
   "metadata": {},
   "source": [
    "32) Compute autocorrelations for the first 10 lags of ser. Find out which lag has the largest correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "052982b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22, 0.24, 0.61, 0.25, 0.36, 0.43, 0.18, -0.03, 0.44, 0.23]\n",
      "Lag having highest correlation:  3\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series(np.arange(20) + np.random.normal(1, 10, 20))\n",
    "\n",
    "autocorrelations = [ser.autocorr(i).round(2) for i in range(11)]\n",
    "print(autocorrelations[1:])\n",
    "print('Lag having highest correlation: ', np.argmax(np.abs(autocorrelations[1:]))+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae48ebc",
   "metadata": {},
   "source": [
    "33) Import every 50th row of BostonHousing dataset as a dataframe.\n",
    "    https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "09888bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         crim    zn  indus  chas    nox     rm    age     dis   rad    tax  \\\n",
      "0     0.00632  18.0   2.31   0.0  0.538  6.575   65.2  4.0900   1.0  296.0   \n",
      "50    0.08873  21.0   5.64   0.0  0.439  5.963   45.7  6.8147   4.0  243.0   \n",
      "100   0.14866   0.0   8.56   0.0  0.520  6.727   79.9  2.7778   5.0  384.0   \n",
      "150   1.65660   0.0  19.58   0.0  0.871  6.122   97.3  1.6180   5.0  403.0   \n",
      "200   0.01778  95.0   1.47   0.0  0.403  7.135   13.9  7.6534   3.0  402.0   \n",
      "250   0.14030  22.0   5.86   0.0  0.431  6.487   13.0  7.3967   7.0  330.0   \n",
      "300   0.04417  70.0   2.24   0.0  0.400  6.871   47.4  7.8278   5.0  358.0   \n",
      "350   0.06211  40.0   1.25   0.0  0.429  6.490   44.4  8.7921   1.0  335.0   \n",
      "400  25.04610   0.0  18.10   0.0  0.693  5.987  100.0  1.5888  24.0  666.0   \n",
      "450   6.71772   0.0  18.10   0.0  0.713  6.749   92.6  2.3236  24.0  666.0   \n",
      "500   0.22438   0.0   9.69   0.0  0.585  6.027   79.7  2.4982   6.0  391.0   \n",
      "\n",
      "     ptratio       b  lstat  medv  \n",
      "0       15.3  396.90   4.98  24.0  \n",
      "50      16.8  395.56  13.45  19.7  \n",
      "100     20.9  394.76   9.42  27.5  \n",
      "150     14.7  372.80  14.10  21.5  \n",
      "200     17.0  384.30   4.45  32.9  \n",
      "250     19.1  396.28   5.90  24.4  \n",
      "300     14.8  390.86   6.07  24.8  \n",
      "350     19.7  396.90   5.98  22.9  \n",
      "400     20.2  396.90  26.77   5.6  \n",
      "450     20.2    0.32  17.44  13.4  \n",
      "500     19.2  396.90  14.33  16.8  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv', chunksize=50)\n",
    "df2 = pd.concat([chunk.iloc[0] for chunk in df], axis=1)\n",
    "df2 = df2.transpose()\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f10cbec",
   "metadata": {},
   "source": [
    "34) Import the boston housing dataset, but while importing change the 'medv' (median house value) column so that values < 25 becomes ‘Low’ and > 25 becomes ‘High’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c9c39256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
      "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
      "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
      "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
      "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
      "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
      "\n",
      "        b  lstat  medv  \n",
      "0  396.90   4.98   Low  \n",
      "1  396.90   9.14   Low  \n",
      "2  392.83   4.03  High  \n",
      "3  394.63   2.94  High  \n",
      "4  396.90   5.33  High  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv', \n",
    "                 converters={'medv': lambda x: 'High' if float(x) > 25 else 'Low'})\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83078db",
   "metadata": {},
   "source": [
    "35) Create a dataframe with rows as strides from the series \"L\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ea9dfeba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 2,  3,  4,  5],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 6,  7,  8,  9],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [10, 11, 12, 13]], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = pd.Series(range(15))\n",
    "\n",
    "def gen_strides(a, stride_len=5, window_len=5):\n",
    "    n_strides = ((a.size-window_len)//stride_len) + 1\n",
    "    return np.array([a[s:(s+window_len)] for s in np.arange(0, a.size, stride_len)[:n_strides]])\n",
    "\n",
    "gen_strides(L, stride_len=2, window_len=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b36f890",
   "metadata": {},
   "source": [
    "36) Import ‘crim’ and ‘medv’ columns of the BostonHousing dataset as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "33ecddbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      crim  medv\n",
      "0  0.00632  24.0\n",
      "1  0.02731  21.6\n",
      "2  0.02729  34.7\n",
      "3  0.03237  33.4\n",
      "4  0.06905  36.2\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv', usecols=['crim', 'medv'])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d830c591",
   "metadata": {},
   "source": [
    "37) Get the number of rows, columns, datatype and summary statistics of each column of the Cars93 dataset. Also get the numpy array and list equivalent of the dataframe.\n",
    "\n",
    "https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2c1fe83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93, 27)\n",
      "Manufacturer           object\n",
      "Model                  object\n",
      "Type                   object\n",
      "Min.Price             float64\n",
      "Price                 float64\n",
      "Max.Price             float64\n",
      "MPG.city              float64\n",
      "MPG.highway           float64\n",
      "AirBags                object\n",
      "DriveTrain             object\n",
      "Cylinders              object\n",
      "EngineSize            float64\n",
      "Horsepower            float64\n",
      "RPM                   float64\n",
      "Rev.per.mile          float64\n",
      "Man.trans.avail        object\n",
      "Fuel.tank.capacity    float64\n",
      "Passengers            float64\n",
      "Length                float64\n",
      "Wheelbase             float64\n",
      "Width                 float64\n",
      "Turn.circle           float64\n",
      "Rear.seat.room        float64\n",
      "Luggage.room          float64\n",
      "Weight                float64\n",
      "Origin                 object\n",
      "Make                   object\n",
      "dtype: object\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'get_dtype_counts'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mprint\u001b[39m(df\u001b[39m.\u001b[39mdtypes)\n\u001b[0;32m      9\u001b[0m \u001b[39m# how many columns under each dtype\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[39mprint\u001b[39m(df\u001b[39m.\u001b[39;49mget_dtype_counts())\n\u001b[0;32m     11\u001b[0m \u001b[39mprint\u001b[39m(df\u001b[39m.\u001b[39mdtypes\u001b[39m.\u001b[39mvalue_counts())\n\u001b[0;32m     13\u001b[0m \u001b[39m# summary statistics\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chamu\\python-practice\\my_environment\\Lib\\site-packages\\pandas\\core\\generic.py:5902\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5895\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   5896\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[0;32m   5897\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[0;32m   5898\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[0;32m   5899\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5900\u001b[0m ):\n\u001b[0;32m   5901\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[1;32m-> 5902\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'get_dtype_counts'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "#  number of rows and columns\n",
    "print(df.shape)\n",
    "\n",
    "# datatypes\n",
    "print(df.dtypes)\n",
    "\n",
    "# how many columns under each dtype\n",
    "print(df.get_dtype_counts())\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "# summary statistics\n",
    "df_stats = df.describe()\n",
    "\n",
    "# numpy array \n",
    "df_arr = df.values\n",
    "\n",
    "# list\n",
    "df_list = df.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e458e997",
   "metadata": {},
   "source": [
    "38) Which manufacturer, model and type has the highest Price? What is the row and column number of the cell with the highest Price value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f70df19d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.9"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "\n",
    "# Solution\n",
    "# Get Manufacturer with highest price\n",
    "df.loc[df.Price == np.max(df.Price), ['Manufacturer', 'Model', 'Type']]\n",
    "\n",
    "# Get Row and Column number\n",
    "row, col = np.where(df.values == np.max(df.Price))\n",
    "\n",
    "# Get the value\n",
    "df.iat[row[0], col[0]]\n",
    "df.iloc[row[0], col[0]]\n",
    "\n",
    "# Alternates\n",
    "df.at[row[0], 'Price']\n",
    "# df.get_value(row[0], 'Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e81856",
   "metadata": {},
   "source": [
    "39) Rename the column \"Type\" as \"CarType\" in the previous data and replace the ‘.’ in column names with ‘_’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "33e517e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Manufacturer', 'Model', 'CarType', 'Min_Price', 'Price', 'Max_Price',\n",
      "       'MPG_city', 'MPG_highway', 'AirBags', 'DriveTrain', 'Cylinders',\n",
      "       'EngineSize', 'Horsepower', 'RPM', 'Rev_per_mile', 'Man_trans_avail',\n",
      "       'Fuel_tank_capacity', 'Passengers', 'Length', 'Wheelbase', 'Width',\n",
      "       'Turn_circle', 'Rear_seat_room', 'Luggage_room', 'Weight', 'Origin',\n",
      "       'Make'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# print(df.columns)\n",
    "\n",
    "# Step 1:\n",
    "\n",
    "df=df.rename(columns = {'Type':'CarType'})\n",
    "# or\n",
    "df.columns.values[2] = \"CarType\"\n",
    "\n",
    "\n",
    "# Step 2:\n",
    "df.columns = df.columns.map(lambda x: x.replace('.', '_'))\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5989022c",
   "metadata": {},
   "source": [
    "40) Check if the data from #37 has any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e9f7e0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "# Solution\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed881438",
   "metadata": {},
   "source": [
    "41) Count the number of missing values in each column of the previous data. Which column has the maximum number of missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf14525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5abbc84",
   "metadata": {},
   "source": [
    "42) Replace missing values in Min.Price and Max.Price columns with their respective mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91acfe3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1d26407",
   "metadata": {},
   "source": [
    "43) In the previous data, use apply method to replace the missing values in Min.Price with the column’s mean and those in Max.Price with the column’s median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb6209b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80c193bc",
   "metadata": {},
   "source": [
    "44) Get the first column (a) in the data as a dataframe (rather than as a Series)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be2fbaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83334c4f",
   "metadata": {},
   "source": [
    "45) Actually 3 questions.\n",
    "\n",
    "In the data, interchange columns 'a' and 'c'.\n",
    "\n",
    "Create a generic function to interchange two columns, without hardcoding column names.\n",
    "\n",
    "Sort the columns in reverse alphabetical order, that is colume 'e' first through column 'a' last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8706e8d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd957988",
   "metadata": {},
   "source": [
    "46) Change the pandas display settings on printing the dataframe so it shows a maximum of 10 rows and 10 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bd512a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f69a323b",
   "metadata": {},
   "source": [
    "47) Suppress scientific notations like ‘e-03’ in df and print upto 4 numbers after decimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485aa0b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bfa22aec",
   "metadata": {},
   "source": [
    "48) Format the values in column 'random' of df as percentages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d4f4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.random(4), columns=['random'])\n",
    "df\n",
    "#>      random\n",
    "#> 0    .689723\n",
    "#> 1    .957224\n",
    "#> 2    .159157\n",
    "#> 3    .21082"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829030ce",
   "metadata": {},
   "source": [
    "49) From the cars data, filter the 'Manufacturer', 'Model' and 'Type' for every 20th row starting from 1st (row 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b439593c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d38155b7",
   "metadata": {},
   "source": [
    "50) In the cars data, Replace NaNs with ‘missing’ in columns 'Manufacturer', 'Model' and 'Type' and create a index as a combination of these three columns and check if the index is a primary key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf131e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d01c9b73",
   "metadata": {},
   "source": [
    "51) Find the row position of the 5th largest value of column 'a' in df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15321302",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1, 30, 30).reshape(10,-1), columns=list('abc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df76d19",
   "metadata": {},
   "source": [
    "52) In ser, find the position of the 2nd largest value greater than the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61330d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(np.random.randint(1, 100, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaae1b8",
   "metadata": {},
   "source": [
    "53) Get the last two rows of df whose row sum is greater than 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab30612",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(10, 40, 60).reshape(-1, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4dac7e",
   "metadata": {},
   "source": [
    "54) Replace all values of ser in the lower 5%ile and greater than 95%ile with respective 5th and 95th %ile value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bc91ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(np.logspace(-2, 2, 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407723d9",
   "metadata": {},
   "source": [
    "55) Reshape df to the largest possible square with negative values removed. Drop the smallest values if need be. The order of the positive numbers in the result should remain the same as the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebc8dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(-20, 50, 100).reshape(10,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa891f3",
   "metadata": {},
   "source": [
    "56) Swap rows 1 and 2 in df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca60052",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(25).reshape(5, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97144928",
   "metadata": {},
   "source": [
    "57) Reverse all the rows of dataframe df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac3cc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(25).reshape(5, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f09f84f",
   "metadata": {},
   "source": [
    "58) Get one-hot encodings for column 'a' in the dataframe df and append it as columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59860b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(25).reshape(5,-1), columns=list('abcde'))\n",
    "    a   b   c   d   e\n",
    "0   0   1   2   3   4\n",
    "1   5   6   7   8   9\n",
    "2  10  11  12  13  14\n",
    "3  15  16  17  18  19\n",
    "4  20  21  22  23  24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5295b8b",
   "metadata": {},
   "source": [
    "59) Obtain the column name with the highest number of row-wise maximum’s in df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5083160c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 40).reshape(10, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fcf24b",
   "metadata": {},
   "source": [
    "60) Create a new column such that, each row contains the row number of nearest row-record by euclidean distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0719c737",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 40).reshape(10, -1), columns=list('pqrs'), index=list('abcdefghij'))\n",
    "df\n",
    "#     p   q   r   s\n",
    "# a  57  77  13  62\n",
    "# b  68   5  92  24\n",
    "# c  74  40  18  37\n",
    "# d  80  17  39  60\n",
    "# e  93  48  85  33\n",
    "# f  69  55   8  11\n",
    "# g  39  23  88  53\n",
    "# h  63  28  25  61\n",
    "# i  18   4  73   7\n",
    "# j  79  12  45  34"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eb1791",
   "metadata": {},
   "source": [
    "61) Compute maximum possible absolute correlation value of each column against other columns in df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baee6e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1), columns=list('pqrstuvwxy'), index=list('abcdefgh'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828ef471",
   "metadata": {},
   "source": [
    "62) Compute the minimum-by-maximum for every row of df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7368340",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971d2276",
   "metadata": {},
   "source": [
    "63) Create a new column 'penultimate' which has the second largest value of each row of df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c6865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529c1042",
   "metadata": {},
   "source": [
    "64) Normalize all columns of df by subtracting the column mean and divide by standard deviation.\n",
    "Range all columns of df such that the minimum value in each column is 0 and max is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da28502",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af26e808",
   "metadata": {},
   "source": [
    "65) Compute the correlation of each row of df with its succeeding row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fca730",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57341a09",
   "metadata": {},
   "source": [
    "66) Replace both values in both diagonals of df with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721432ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 100).reshape(10, -1))\n",
    "df\n",
    "#     0   1   2   3   4   5   6   7   8   9\n",
    "# 0  11  46  26  44  11  62  18  70  68  26\n",
    "# 1  87  71  52  50  81  43  83  39   3  59\n",
    "# 2  47  76  93  77  73   2   2  16  14  26\n",
    "# 3  64  18  74  22  16  37  60   8  66  39\n",
    "# 4  10  18  39  98  25   8  32   6   3  29\n",
    "# 5  29  91  27  86  23  84  28  31  97  10\n",
    "# 6  37  71  70  65   4  72  82  89  12  97\n",
    "# 7  65  22  97  75  17  10  43  78  12  77\n",
    "# 8  47  57  96  55  17  83  61  85  26  86\n",
    "# 9  76  80  28  45  77  12  67  80   7  63\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202c483b",
   "metadata": {},
   "source": [
    "67) Using a key in a grouped data frame. From df_grouped, get the group belonging to 'apple' as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8028ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'col1': ['apple', 'banana', 'orange'] * 3,\n",
    "                   'col2': np.random.rand(9),\n",
    "                   'col3': np.random.randint(0, 15, 9)})\n",
    "\n",
    "df_grouped = df.groupby(['col1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2cb901",
   "metadata": {},
   "source": [
    "68) In df, find the second largest value of 'taste' for 'banana'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7209bc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n",
    "                   'rating': np.random.rand(9),\n",
    "                   'price': np.random.randint(0, 15, 9)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bde89cb",
   "metadata": {},
   "source": [
    "69) In df, Compute the mean price of every fruit, while keeping the fruit as another column instead of an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a4c8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n",
    "                   'rating': np.random.rand(9),\n",
    "                   'price': np.random.randint(0, 15, 9)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5eaa372",
   "metadata": {},
   "source": [
    "70) Join dataframes df1 and df2 by ‘fruit-pazham’ and ‘weight-kilo’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a250adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n",
    "                    'weight': ['high', 'medium', 'low'] * 3,\n",
    "                    'price': np.random.randint(0, 15, 9)})\n",
    "\n",
    "df2 = pd.DataFrame({'pazham': ['apple', 'orange', 'pine'] * 2,\n",
    "                    'kilo': ['high', 'low'] * 3,\n",
    "                    'price': np.random.randint(0, 15, 6)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57adb8fe",
   "metadata": {},
   "source": [
    "71) Get the positions where the value of two columns match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43cc070",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'fruit1': np.random.choice(['apple', 'orange', 'banana'], 10),\n",
    "                    'fruit2': np.random.choice(['apple', 'orange', 'banana'], 10)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7da5c86",
   "metadata": {},
   "source": [
    "72) Create two new columns in df, one of which is a lag1 (shift column a down by 1 row) of column ‘a’ and the other is a lead1 (shift column b up by 1 row)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e531adc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1, 100, 20).reshape(-1, 4), columns = list('abcd'))\n",
    "\n",
    "    a   b   c   d\n",
    "0  66  34  76  47\n",
    "1  20  86  10  81\n",
    "2  75  73  51  28\n",
    "3   1   1   9  83\n",
    "4  30  47  67   4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501a01f7",
   "metadata": {},
   "source": [
    "73) Get the frequency of unique values in the entire dataframe df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22b1df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1, 10, 20).reshape(-1, 4), columns = list('abcd'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5d182d",
   "metadata": {},
   "source": [
    "74) Split the string column in df to form a dataframe with 3 columns as shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8a2bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([\"STD, City    State\",\n",
    "\"33, Kolkata    West Bengal\",\n",
    "\"44, Chennai    Tamil Nadu\",\n",
    "\"40, Hyderabad    Telengana\",\n",
    "\"80, Bangalore    Karnataka\"], columns=['row'])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a90037ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.arange(7))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "357ec78291cf388eeacd62e271c6b188c6b9f92b882d7927ff21aa77b4c7f673"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
